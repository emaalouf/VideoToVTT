import axios from 'axios';
import fs from 'fs-extra';
import colors from 'colors';

export class LLMTranslator {
  constructor(config = {}) {
    this.apiUrl = config.apiUrl || process.env.LLM_API_URL || 'https://openrouter.ai/api/v1/chat/completions';
    this.model = config.model || process.env.LLM_MODEL || null; // Will be selected dynamically
    this.apiKey = config.apiKey || process.env.LLM_API_KEY || process.env.OPENROUTER_API_KEY;
    this.timeout = config.timeout || 60000; // 60 seconds for cloud APIs
    this.selectedModel = null;
    this.availableCredits = null;
    this.modelsList = [];
  }

  async checkCredits() {
    try {
      console.log(colors.blue('üí≥ Checking OpenRouter credits...'));
      
      const response = await axios.get('https://openrouter.ai/api/v1/credits', {
        headers: {
          'Authorization': `Bearer ${this.apiKey}`
        }
      });

      const { total_credits, total_usage } = response.data.data;
      this.availableCredits = total_credits - total_usage;
      
      console.log(colors.green(`‚úÖ Credits Status:`));
      console.log(colors.cyan(`   üí∞ Total Credits: ${total_credits}`));
      console.log(colors.cyan(`   üìä Used Credits: ${total_usage.toFixed(4)}`));
      console.log(colors.green(`   üéØ Available Credits: ${this.availableCredits.toFixed(4)}`));
      
      return this.availableCredits;
    } catch (error) {
      console.log(colors.yellow('‚ö†Ô∏è  Could not check credits:'), error.message);
      return null;
    }
  }

  async fetchAvailableModels() {
    try {
      console.log(colors.blue('ü§ñ Fetching available models...'));
      
      const response = await axios.get('https://openrouter.ai/api/v1/models');
      this.modelsList = response.data.data;
      
      console.log(colors.green(`‚úÖ Found ${this.modelsList.length} available models`));
      return this.modelsList;
    } catch (error) {
      console.log(colors.yellow('‚ö†Ô∏è  Could not fetch models:'), error.message);
      return [];
    }
  }

  selectBestModel() {
    if (this.model) {
      // If model is explicitly set, use it
      this.selectedModel = this.model;
      console.log(colors.cyan(`üéØ Using configured model: ${this.selectedModel}`));
      return this.selectedModel;
    }

    if (!this.modelsList.length) {
      // Fallback to a reliable default
      this.selectedModel = 'deepseek/deepseek-r1-0528-qwen3-8b:free';
      console.log(colors.yellow(`‚ö†Ô∏è  Using fallback model: ${this.selectedModel}`));
      return this.selectedModel;
    }

    // Prioritize models based on cost and quality
    const preferredModels = [
      // Free models (best choice)
      'deepseek/deepseek-r1-0528-qwen3-8b:free',
      'deepseek/deepseek-r1-0528:free',
      
      // Very cheap but high quality
      'deepseek/deepseek-r1-0528-qwen3-8b',
      'google/gemma-2b-it',
      'deepseek/deepseek-r1-0528',
      
      // Fallback to other good models
      'meta-llama/llama-3.1-8b-instruct',
      'openai/gpt-4o-mini',
      'anthropic/claude-3-haiku'
    ];

    // Find the first available preferred model
    for (const preferredModel of preferredModels) {
      const model = this.modelsList.find(m => m.id === preferredModel);
      if (model) {
        this.selectedModel = model.id;
        const isFree = parseFloat(model.pricing.prompt) === 0 && parseFloat(model.pricing.completion) === 0;
        const cost = isFree ? 'FREE' : `$${model.pricing.prompt}/1K tokens (prompt), $${model.pricing.completion}/1K tokens (completion)`;
        
        console.log(colors.green(`üéØ Selected model: ${model.name}`));
        console.log(colors.cyan(`   üì¶ Model ID: ${model.id}`));
        console.log(colors.cyan(`   üí∞ Cost: ${cost}`));
        console.log(colors.cyan(`   üìè Context: ${model.context_length} tokens`));
        
        return this.selectedModel;
      }
    }

    // If no preferred model found, use the first free model
    const freeModel = this.modelsList.find(m => 
      parseFloat(m.pricing.prompt) === 0 && parseFloat(m.pricing.completion) === 0
    );
    
    if (freeModel) {
      this.selectedModel = freeModel.id;
      console.log(colors.green(`üéØ Selected free model: ${freeModel.name} (${freeModel.id})`));
      return this.selectedModel;
    }

    // Last resort: use the cheapest model
    const cheapestModel = this.modelsList
      .filter(m => parseFloat(m.pricing.prompt) > 0 || parseFloat(m.pricing.completion) > 0)
      .sort((a, b) => (parseFloat(a.pricing.prompt) + parseFloat(a.pricing.completion)) - 
                      (parseFloat(b.pricing.prompt) + parseFloat(b.pricing.completion)))[0];

    if (cheapestModel) {
      this.selectedModel = cheapestModel.id;
      console.log(colors.yellow(`üéØ Selected cheapest model: ${cheapestModel.name} (${cheapestModel.id})`));
      return this.selectedModel;
    }

    // Ultimate fallback
    this.selectedModel = 'deepseek/deepseek-r1-0528-qwen3-8b:free';
    console.log(colors.red(`‚ö†Ô∏è  Using ultimate fallback: ${this.selectedModel}`));
    return this.selectedModel;
  }

  async initialize() {
    console.log(colors.rainbow('üöÄ Initializing OpenRouter LLM Translator...\n'));
    
    if (!this.apiKey) {
      console.log(colors.red('‚ùå No OpenRouter API key found!'));
      return false;
    }

    // Check credits first
    await this.checkCredits();
    
    // Fetch available models
    await this.fetchAvailableModels();
    
    // Select the best model
    this.selectBestModel();
    
    return true;
  }

  async translateVTT(vttContent, targetLanguage, sourceLanguage = 'auto') {
    console.log(colors.blue(`üåê Translating VTT content to ${targetLanguage.toUpperCase()}...`));

    try {
      // Parse VTT content
      const vttLines = vttContent.split('\n');
      const translatedLines = [];
      let subtitleCount = 0;

      let currentSubtitle = '';
      let isSubtitleLine = false;

      for (let i = 0; i < vttLines.length; i++) {
        const line = vttLines[i].trim();

        // Skip WEBVTT header
        if (line.startsWith('WEBVTT')) {
          translatedLines.push(line);
          continue;
        }

        // Skip empty lines
        if (line === '') {
          translatedLines.push('');
          continue;
        }

        // Skip timestamp lines (format: 00:00:00.000 --> 00:00:00.000)
        if (line.includes('-->')) {
          translatedLines.push(line);
          isSubtitleLine = true;
          continue;
        }

        // Skip cue settings (lines that start with alignment, position, etc.)
        if (line.match(/^(align:|line:|position:|size:|vertical:)/)) {
          translatedLines.push(line);
          continue;
        }

        // This is subtitle text - translate it
        if (isSubtitleLine && line !== '') {
          subtitleCount++;
          console.log(colors.cyan(`   üìù Subtitle ${subtitleCount} (${targetLanguage.toUpperCase()}): "${line.substring(0, 60)}${line.length > 60 ? '...' : ''}"`));
          
          const translatedText = await this.translateText(line, targetLanguage, sourceLanguage);
          translatedLines.push(translatedText);
          isSubtitleLine = false;
        } else {
          translatedLines.push(line);
        }
      }

      const translatedVTT = translatedLines.join('\n');
      console.log(colors.green(`‚úÖ VTT translation to ${targetLanguage.toUpperCase()} completed (${subtitleCount} subtitles translated)`));
      return translatedVTT;

    } catch (error) {
      console.error(colors.red(`‚ùå VTT translation failed:`, error.message));
      throw error;
    }
  }

  async translateText(text, targetLanguage, sourceLanguage = 'auto') {
    if (!text.trim()) return text;

    try {
      console.log(colors.blue(`üîÑ Translating to ${targetLanguage.toUpperCase()}: "${text.substring(0, 50)}${text.length > 50 ? '...' : ''}"`));
      
      const prompt = this.createTranslationPrompt(text, targetLanguage, sourceLanguage);
      
      let translatedText;
      
      // Try different LLM APIs based on the configured URL
      if (this.apiUrl.includes('openrouter')) {
        translatedText = await this.translateWithOpenRouter(prompt);
      } else if (this.apiUrl.includes('ollama')) {
        translatedText = await this.translateWithOllama(prompt);
      } else if (this.apiUrl.includes('deepseek')) {
        translatedText = await this.translateWithDeepSeek(prompt);
      } else if (this.apiUrl.includes('mistral')) {
        translatedText = await this.translateWithMistral(prompt);
      } else {
        // Default to OpenRouter-compatible format
        translatedText = await this.translateWithOpenRouter(prompt);
      }
      
      console.log(colors.green(`‚úÖ ${targetLanguage.toUpperCase()} Translation: "${translatedText.substring(0, 80)}${translatedText.length > 80 ? '...' : ''}"`));
      return translatedText;

    } catch (error) {
      console.error(colors.red(`‚ùå Translation failed for ${targetLanguage.toUpperCase()}: "${text.substring(0, 50)}..."`));
      console.error(colors.red(`   Error: ${error.message}`));
      return text; // Return original text if translation fails
    }
  }

  createTranslationPrompt(text, targetLanguage, sourceLanguage) {
    const languageNames = {
      'ar': 'Arabic',
      'en': 'English',
      'fr': 'French',
      'es': 'Spanish',
      'it': 'Italian'
    };

    const targetLangName = languageNames[targetLanguage] || targetLanguage;
    const sourceLangName = sourceLanguage === 'auto' ? 'detected language' : (languageNames[sourceLanguage] || sourceLanguage);

    return `Translate the following text from ${sourceLangName} to ${targetLangName}. 
Only return the translated text without any explanations or additional content.
Preserve the original meaning and tone.

Text to translate: "${text}"

Translation:`;
  }

  async translateWithOllama(prompt) {
    const response = await axios.post(this.apiUrl, {
      model: this.model,
      prompt: prompt,
      stream: false,
      options: {
        temperature: 0.3, // Lower temperature for more consistent translations
        top_p: 0.9,
        max_tokens: 500
      }
    }, {
      timeout: this.timeout,
      headers: {
        'Content-Type': 'application/json'
      }
    });

    return response.data.response.trim();
  }

  async translateWithDeepSeek(prompt) {
    const response = await axios.post(this.apiUrl, {
      model: this.model,
      messages: [
        {
          role: "user",
          content: prompt
        }
      ],
      temperature: 0.3,
      max_tokens: 500
    }, {
      timeout: this.timeout,
      headers: {
        'Content-Type': 'application/json',
        'Authorization': `Bearer ${this.apiKey}`
      }
    });

    return response.data.choices[0].message.content.trim();
  }

  async translateWithMistral(prompt) {
    const response = await axios.post(this.apiUrl, {
      model: this.model,
      messages: [
        {
          role: "user",
          content: prompt
        }
      ],
      temperature: 0.3,
      max_tokens: 500
    }, {
      timeout: this.timeout,
      headers: {
        'Content-Type': 'application/json',
        'Authorization': `Bearer ${this.apiKey}`
      }
    });

    return response.data.choices[0].message.content.trim();
  }

  async translateWithOpenRouter(prompt) {
    if (!this.apiKey) {
      throw new Error('OpenRouter API key is required. Please set OPENROUTER_API_KEY or LLM_API_KEY in your environment.');
    }

    const modelToUse = this.selectedModel || this.model || 'deepseek/deepseek-r1-0528-qwen3-8b:free';

    const response = await axios.post(this.apiUrl, {
      model: modelToUse,
      messages: [
        {
          role: "system",
          content: "You are a professional translator. Translate the given text accurately while preserving the original meaning and tone. Return ONLY the translated text without any explanations."
        },
        {
          role: "user",
          content: prompt
        }
      ],
      temperature: 0.2,
      max_tokens: 1000,
      top_p: 0.9
    }, {
      timeout: this.timeout,
      headers: {
        'Content-Type': 'application/json',
        'Authorization': `Bearer ${this.apiKey}`,
        'HTTP-Referer': 'https://github.com/your-username/VideoToVTT',
        'X-Title': 'VideoToVTT Processor'
      }
    });

    // Log usage info if available
    if (response.data.usage) {
      const { prompt_tokens, completion_tokens, total_tokens } = response.data.usage;
      console.log(colors.gray(`   üìä Tokens: ${prompt_tokens} prompt + ${completion_tokens} completion = ${total_tokens} total`));
    }

    return response.data.choices[0].message.content.trim();
  }

  async translateWithGenericAPI(prompt) {
    const response = await axios.post(this.apiUrl, {
      prompt: prompt,
      model: this.model,
      temperature: 0.3,
      max_tokens: 500
    }, {
      timeout: this.timeout,
      headers: {
        'Content-Type': 'application/json',
        ...(this.apiKey && { 'Authorization': `Bearer ${this.apiKey}` })
      }
    });

    // Try to extract response from common response formats
    if (response.data.response) {
      return response.data.response.trim();
    } else if (response.data.choices && response.data.choices[0]) {
      return response.data.choices[0].message.content.trim();
    } else if (response.data.text) {
      return response.data.text.trim();
    } else {
      throw new Error('Unexpected response format from LLM API');
    }
  }

  async testConnection() {
    try {
      console.log(colors.blue('üîç Testing LLM connection...'));
      
      if (!this.apiKey) {
        console.log(colors.red('‚ùå No API key found. Please set OPENROUTER_API_KEY or LLM_API_KEY in your environment.'));
        return false;
      }

      // Initialize if not already done
      if (!this.selectedModel) {
        await this.initialize();
      }
      
      const testText = await this.translateText('Hello, world!', 'fr', 'en');
      
      if (testText && testText !== 'Hello, world!' && !testText.includes('[FR]')) {
        console.log(colors.green('‚úÖ LLM connection successful!'));
        console.log(colors.cyan(`Test translation: "Hello, world!" ‚Üí "${testText}"`));
        console.log(colors.cyan(`Using model: ${this.selectedModel || this.model}`));
        return true;
      } else {
        console.log(colors.yellow('‚ö†Ô∏è  LLM responded but translation may not be working correctly'));
        console.log(colors.yellow(`Response: "${testText}"`));
        return false;
      }
    } catch (error) {
      console.log(colors.red('‚ùå LLM connection failed:'), error.message);
      if (error.response) {
        console.log(colors.red(`Status: ${error.response.status}`));
        console.log(colors.red(`Data: ${JSON.stringify(error.response.data)}`));
      }
      console.log(colors.yellow('üí° Will use placeholder translations instead'));
      return false;
    }
  }

  // Fallback method for when LLM is not available
  createPlaceholderTranslation(text, targetLanguage) {
    const languagePrefixes = {
      'ar': '[AR]',
      'en': '[EN]',
      'fr': '[FR]',
      'es': '[ES]',
      'it': '[IT]'
    };

    const prefix = languagePrefixes[targetLanguage] || `[${targetLanguage.toUpperCase()}]`;
    return `${prefix} ${text}`;
  }
}

// Export utility function for easy language detection
export function detectTextLanguage(text) {
  const arabicPattern = /[\u0600-\u06FF]/;
  const frenchPattern = /[√†√¢√§√ß√©√®√™√´√Ø√Æ√¥√∂√π√ª√º√ø√¶≈ì]/i;
  const spanishPattern = /[√±√°√©√≠√≥√∫√º¬ø¬°]/i;
  const italianPattern = /[√†√®√©√¨√≠√Æ√≤√≥√π√∫]/i;
  const englishPattern = /^[a-zA-Z\s.,!?'"()-]+$/;

  if (arabicPattern.test(text)) {
    return 'ar';
  } else if (frenchPattern.test(text)) {
    return 'fr';
  } else if (spanishPattern.test(text)) {
    return 'es';
  } else if (italianPattern.test(text)) {
    return 'it';
  } else if (englishPattern.test(text)) {
    return 'en';
  } else {
    return 'auto'; // Unknown language
  }
} 